{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 185.0,
  "eval_steps": 500,
  "global_step": 555,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.0,
      "grad_norm": 3.359201431274414,
      "learning_rate": 5e-06,
      "loss": 0.068,
      "step": 3
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.06899816039949655,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.214211940765381,
      "learning_rate": 1e-05,
      "loss": 0.0659,
      "step": 6
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0667645636945963,
      "step": 6
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.994910955429077,
      "learning_rate": 1.5e-05,
      "loss": 0.0616,
      "step": 9
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.06005336716771126,
      "step": 9
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.7558491230010986,
      "learning_rate": 2e-05,
      "loss": 0.0557,
      "step": 12
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.05418269857764244,
      "step": 12
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.3396761417388916,
      "learning_rate": 2.5e-05,
      "loss": 0.0507,
      "step": 15
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.04507836792618036,
      "step": 15
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.8983221054077148,
      "learning_rate": 3e-05,
      "loss": 0.0422,
      "step": 18
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.036857057735323905,
      "step": 18
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.3403433561325073,
      "learning_rate": 3.5e-05,
      "loss": 0.0372,
      "step": 21
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.03340934822335839,
      "step": 21
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.7496346831321716,
      "learning_rate": 4e-05,
      "loss": 0.0293,
      "step": 24
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.023864988423883914,
      "step": 24
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.5380186438560486,
      "learning_rate": 4.5e-05,
      "loss": 0.0261,
      "step": 27
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.02149705197662115,
      "step": 27
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.7102105617523193,
      "learning_rate": 5e-05,
      "loss": 0.0219,
      "step": 30
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.018017462454736233,
      "step": 30
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.6242348551750183,
      "learning_rate": 5.500000000000001e-05,
      "loss": 0.0193,
      "step": 33
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.016499107657000422,
      "step": 33
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.21082505583763123,
      "learning_rate": 6e-05,
      "loss": 0.016,
      "step": 36
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.011227645864710211,
      "step": 36
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.3689943552017212,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.0142,
      "step": 39
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.008884053770452737,
      "step": 39
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.3816050589084625,
      "learning_rate": 7e-05,
      "loss": 0.0124,
      "step": 42
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.007054202584549784,
      "step": 42
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.15280646085739136,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.01,
      "step": 45
    },
    {
      "epoch": 15.0,
      "eval_loss": 0.00664656322915107,
      "step": 45
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.252564400434494,
      "learning_rate": 8e-05,
      "loss": 0.0082,
      "step": 48
    },
    {
      "epoch": 16.0,
      "eval_loss": 0.004184309288393706,
      "step": 48
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.22198522090911865,
      "learning_rate": 8.5e-05,
      "loss": 0.0081,
      "step": 51
    },
    {
      "epoch": 17.0,
      "eval_loss": 0.0032146338315214964,
      "step": 51
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.21912716329097748,
      "learning_rate": 9e-05,
      "loss": 0.0069,
      "step": 54
    },
    {
      "epoch": 18.0,
      "eval_loss": 0.0026627137849573046,
      "step": 54
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.11747993528842926,
      "learning_rate": 9.5e-05,
      "loss": 0.0052,
      "step": 57
    },
    {
      "epoch": 19.0,
      "eval_loss": 0.0022054781496990473,
      "step": 57
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.08610241860151291,
      "learning_rate": 0.0001,
      "loss": 0.0045,
      "step": 60
    },
    {
      "epoch": 20.0,
      "eval_loss": 0.002258236421039328,
      "step": 60
    },
    {
      "epoch": 21.0,
      "grad_norm": 0.13581730425357819,
      "learning_rate": 9.944444444444446e-05,
      "loss": 0.0039,
      "step": 63
    },
    {
      "epoch": 21.0,
      "eval_loss": 0.0017155767156509683,
      "step": 63
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.09454260021448135,
      "learning_rate": 9.888888888888889e-05,
      "loss": 0.0039,
      "step": 66
    },
    {
      "epoch": 22.0,
      "eval_loss": 0.002379907137947157,
      "step": 66
    },
    {
      "epoch": 23.0,
      "grad_norm": 0.06493229418992996,
      "learning_rate": 9.833333333333333e-05,
      "loss": 0.003,
      "step": 69
    },
    {
      "epoch": 23.0,
      "eval_loss": 0.0010293443076079712,
      "step": 69
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.0884825810790062,
      "learning_rate": 9.777777777777778e-05,
      "loss": 0.0031,
      "step": 72
    },
    {
      "epoch": 24.0,
      "eval_loss": 0.0009596221527317539,
      "step": 72
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.05056357756257057,
      "learning_rate": 9.722222222222223e-05,
      "loss": 0.0034,
      "step": 75
    },
    {
      "epoch": 25.0,
      "eval_loss": 0.0009457311389269307,
      "step": 75
    },
    {
      "epoch": 26.0,
      "grad_norm": 0.06073099002242088,
      "learning_rate": 9.666666666666667e-05,
      "loss": 0.0028,
      "step": 78
    },
    {
      "epoch": 26.0,
      "eval_loss": 0.00145045775861945,
      "step": 78
    },
    {
      "epoch": 27.0,
      "grad_norm": 0.07545630633831024,
      "learning_rate": 9.611111111111112e-05,
      "loss": 0.0027,
      "step": 81
    },
    {
      "epoch": 27.0,
      "eval_loss": 0.0024466347647830846,
      "step": 81
    },
    {
      "epoch": 28.0,
      "grad_norm": 0.03179463371634483,
      "learning_rate": 9.555555555555557e-05,
      "loss": 0.0024,
      "step": 84
    },
    {
      "epoch": 28.0,
      "eval_loss": 0.001655690564075485,
      "step": 84
    },
    {
      "epoch": 29.0,
      "grad_norm": 0.026735130697488785,
      "learning_rate": 9.5e-05,
      "loss": 0.0025,
      "step": 87
    },
    {
      "epoch": 29.0,
      "eval_loss": 0.000796760597586399,
      "step": 87
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.018049128353595734,
      "learning_rate": 9.444444444444444e-05,
      "loss": 0.0021,
      "step": 90
    },
    {
      "epoch": 30.0,
      "eval_loss": 0.0009821068771998398,
      "step": 90
    },
    {
      "epoch": 31.0,
      "grad_norm": 0.02671264298260212,
      "learning_rate": 9.388888888888889e-05,
      "loss": 0.0019,
      "step": 93
    },
    {
      "epoch": 31.0,
      "eval_loss": 0.0006273501872783527,
      "step": 93
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.016256039962172508,
      "learning_rate": 9.333333333333334e-05,
      "loss": 0.0018,
      "step": 96
    },
    {
      "epoch": 32.0,
      "eval_loss": 0.0021213465901382734,
      "step": 96
    },
    {
      "epoch": 33.0,
      "grad_norm": 0.04198867455124855,
      "learning_rate": 9.277777777777778e-05,
      "loss": 0.0025,
      "step": 99
    },
    {
      "epoch": 33.0,
      "eval_loss": 0.0008732862603210379,
      "step": 99
    },
    {
      "epoch": 34.0,
      "grad_norm": 0.06193222105503082,
      "learning_rate": 9.222222222222223e-05,
      "loss": 0.0017,
      "step": 102
    },
    {
      "epoch": 34.0,
      "eval_loss": 0.0011651493710814974,
      "step": 102
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.054326172918081284,
      "learning_rate": 9.166666666666667e-05,
      "loss": 0.0017,
      "step": 105
    },
    {
      "epoch": 35.0,
      "eval_loss": 0.0011445654272392858,
      "step": 105
    },
    {
      "epoch": 36.0,
      "grad_norm": 0.03462584689259529,
      "learning_rate": 9.111111111111112e-05,
      "loss": 0.0016,
      "step": 108
    },
    {
      "epoch": 36.0,
      "eval_loss": 0.001464380803372478,
      "step": 108
    },
    {
      "epoch": 37.0,
      "grad_norm": 0.04065277427434921,
      "learning_rate": 9.055555555555556e-05,
      "loss": 0.0017,
      "step": 111
    },
    {
      "epoch": 37.0,
      "eval_loss": 0.0005169213087356184,
      "step": 111
    },
    {
      "epoch": 38.0,
      "grad_norm": 0.022577200084924698,
      "learning_rate": 9e-05,
      "loss": 0.0016,
      "step": 114
    },
    {
      "epoch": 38.0,
      "eval_loss": 0.0031477358716074377,
      "step": 114
    },
    {
      "epoch": 39.0,
      "grad_norm": 0.05883222818374634,
      "learning_rate": 8.944444444444446e-05,
      "loss": 0.002,
      "step": 117
    },
    {
      "epoch": 39.0,
      "eval_loss": 0.000989278015185846,
      "step": 117
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.0206326674669981,
      "learning_rate": 8.888888888888889e-05,
      "loss": 0.0017,
      "step": 120
    },
    {
      "epoch": 40.0,
      "eval_loss": 0.0029143504129024223,
      "step": 120
    },
    {
      "epoch": 41.0,
      "grad_norm": 0.012489630840718746,
      "learning_rate": 8.833333333333333e-05,
      "loss": 0.0014,
      "step": 123
    },
    {
      "epoch": 41.0,
      "eval_loss": 0.0008024180344364141,
      "step": 123
    },
    {
      "epoch": 42.0,
      "grad_norm": 0.018470758572220802,
      "learning_rate": 8.777777777777778e-05,
      "loss": 0.0016,
      "step": 126
    },
    {
      "epoch": 42.0,
      "eval_loss": 0.0007916543479950632,
      "step": 126
    },
    {
      "epoch": 43.0,
      "grad_norm": 0.015262451954185963,
      "learning_rate": 8.722222222222223e-05,
      "loss": 0.0012,
      "step": 129
    },
    {
      "epoch": 43.0,
      "eval_loss": 0.0007472460016288096,
      "step": 129
    },
    {
      "epoch": 44.0,
      "grad_norm": 0.016432475298643112,
      "learning_rate": 8.666666666666667e-05,
      "loss": 0.0013,
      "step": 132
    },
    {
      "epoch": 44.0,
      "eval_loss": 0.0005541670660022646,
      "step": 132
    },
    {
      "epoch": 45.0,
      "grad_norm": 0.007973636500537395,
      "learning_rate": 8.611111111111112e-05,
      "loss": 0.001,
      "step": 135
    },
    {
      "epoch": 45.0,
      "eval_loss": 0.0006798454291129019,
      "step": 135
    },
    {
      "epoch": 46.0,
      "grad_norm": 0.03304942324757576,
      "learning_rate": 8.555555555555556e-05,
      "loss": 0.0017,
      "step": 138
    },
    {
      "epoch": 46.0,
      "eval_loss": 0.0009416080767550739,
      "step": 138
    },
    {
      "epoch": 47.0,
      "grad_norm": 0.014819019474089146,
      "learning_rate": 8.5e-05,
      "loss": 0.0011,
      "step": 141
    },
    {
      "epoch": 47.0,
      "eval_loss": 0.000353405972418841,
      "step": 141
    },
    {
      "epoch": 48.0,
      "grad_norm": 0.024052243679761887,
      "learning_rate": 8.444444444444444e-05,
      "loss": 0.0013,
      "step": 144
    },
    {
      "epoch": 48.0,
      "eval_loss": 0.001342822400329169,
      "step": 144
    },
    {
      "epoch": 49.0,
      "grad_norm": 0.048059720546007156,
      "learning_rate": 8.38888888888889e-05,
      "loss": 0.0012,
      "step": 147
    },
    {
      "epoch": 49.0,
      "eval_loss": 0.000736737154511502,
      "step": 147
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.04144379124045372,
      "learning_rate": 8.333333333333334e-05,
      "loss": 0.001,
      "step": 150
    },
    {
      "epoch": 50.0,
      "eval_loss": 0.0007487110189686064,
      "step": 150
    },
    {
      "epoch": 51.0,
      "grad_norm": 0.039035845547914505,
      "learning_rate": 8.277777777777778e-05,
      "loss": 0.0022,
      "step": 153
    },
    {
      "epoch": 51.0,
      "eval_loss": 0.00042882933885266537,
      "step": 153
    },
    {
      "epoch": 52.0,
      "grad_norm": 0.03484789654612541,
      "learning_rate": 8.222222222222222e-05,
      "loss": 0.0009,
      "step": 156
    },
    {
      "epoch": 52.0,
      "eval_loss": 0.001228624241775833,
      "step": 156
    },
    {
      "epoch": 53.0,
      "grad_norm": 0.032068174332380295,
      "learning_rate": 8.166666666666667e-05,
      "loss": 0.0012,
      "step": 159
    },
    {
      "epoch": 53.0,
      "eval_loss": 0.00042394446791149676,
      "step": 159
    },
    {
      "epoch": 54.0,
      "grad_norm": 0.028844501823186874,
      "learning_rate": 8.111111111111112e-05,
      "loss": 0.0011,
      "step": 162
    },
    {
      "epoch": 54.0,
      "eval_loss": 0.0006143164413515478,
      "step": 162
    },
    {
      "epoch": 55.0,
      "grad_norm": 0.03295154497027397,
      "learning_rate": 8.055555555555556e-05,
      "loss": 0.0013,
      "step": 165
    },
    {
      "epoch": 55.0,
      "eval_loss": 0.000641697394894436,
      "step": 165
    },
    {
      "epoch": 56.0,
      "grad_norm": 0.02945949323475361,
      "learning_rate": 8e-05,
      "loss": 0.001,
      "step": 168
    },
    {
      "epoch": 56.0,
      "eval_loss": 0.0005479339008161333,
      "step": 168
    },
    {
      "epoch": 57.0,
      "grad_norm": 0.01117744855582714,
      "learning_rate": 7.944444444444444e-05,
      "loss": 0.0018,
      "step": 171
    },
    {
      "epoch": 57.0,
      "eval_loss": 0.0007089746861311142,
      "step": 171
    },
    {
      "epoch": 58.0,
      "grad_norm": 0.027049612253904343,
      "learning_rate": 7.88888888888889e-05,
      "loss": 0.001,
      "step": 174
    },
    {
      "epoch": 58.0,
      "eval_loss": 0.0007288591023097979,
      "step": 174
    },
    {
      "epoch": 59.0,
      "grad_norm": 0.007833326235413551,
      "learning_rate": 7.833333333333333e-05,
      "loss": 0.0007,
      "step": 177
    },
    {
      "epoch": 59.0,
      "eval_loss": 0.0009014134855533484,
      "step": 177
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.024069607257843018,
      "learning_rate": 7.777777777777778e-05,
      "loss": 0.0009,
      "step": 180
    },
    {
      "epoch": 60.0,
      "eval_loss": 0.000505966623313725,
      "step": 180
    },
    {
      "epoch": 61.0,
      "grad_norm": 0.02219342812895775,
      "learning_rate": 7.722222222222223e-05,
      "loss": 0.0007,
      "step": 183
    },
    {
      "epoch": 61.0,
      "eval_loss": 0.0004504134092712775,
      "step": 183
    },
    {
      "epoch": 62.0,
      "grad_norm": 0.015999486669898033,
      "learning_rate": 7.666666666666667e-05,
      "loss": 0.001,
      "step": 186
    },
    {
      "epoch": 62.0,
      "eval_loss": 0.00027759396216424647,
      "step": 186
    },
    {
      "epoch": 63.0,
      "grad_norm": 0.01497858576476574,
      "learning_rate": 7.61111111111111e-05,
      "loss": 0.0011,
      "step": 189
    },
    {
      "epoch": 63.0,
      "eval_loss": 0.0002764937657047994,
      "step": 189
    },
    {
      "epoch": 64.0,
      "grad_norm": 0.009973007254302502,
      "learning_rate": 7.555555555555556e-05,
      "loss": 0.0007,
      "step": 192
    },
    {
      "epoch": 64.0,
      "eval_loss": 0.0005451658937090543,
      "step": 192
    },
    {
      "epoch": 65.0,
      "grad_norm": 0.032235026359558105,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.0009,
      "step": 195
    },
    {
      "epoch": 65.0,
      "eval_loss": 0.0003532509777869564,
      "step": 195
    },
    {
      "epoch": 66.0,
      "grad_norm": 0.02597220614552498,
      "learning_rate": 7.444444444444444e-05,
      "loss": 0.0007,
      "step": 198
    },
    {
      "epoch": 66.0,
      "eval_loss": 0.0004166991926467745,
      "step": 198
    },
    {
      "epoch": 67.0,
      "grad_norm": 0.014738038182258606,
      "learning_rate": 7.38888888888889e-05,
      "loss": 0.0006,
      "step": 201
    },
    {
      "epoch": 67.0,
      "eval_loss": 0.0006834198491560528,
      "step": 201
    },
    {
      "epoch": 68.0,
      "grad_norm": 0.03576505929231644,
      "learning_rate": 7.333333333333333e-05,
      "loss": 0.0007,
      "step": 204
    },
    {
      "epoch": 68.0,
      "eval_loss": 0.0003517335560900392,
      "step": 204
    },
    {
      "epoch": 69.0,
      "grad_norm": 0.02639048732817173,
      "learning_rate": 7.277777777777778e-05,
      "loss": 0.0005,
      "step": 207
    },
    {
      "epoch": 69.0,
      "eval_loss": 0.00036256204621167856,
      "step": 207
    },
    {
      "epoch": 70.0,
      "grad_norm": 0.007257938385009766,
      "learning_rate": 7.222222222222222e-05,
      "loss": 0.0007,
      "step": 210
    },
    {
      "epoch": 70.0,
      "eval_loss": 0.0004470684354600962,
      "step": 210
    },
    {
      "epoch": 71.0,
      "grad_norm": 0.04714304208755493,
      "learning_rate": 7.166666666666667e-05,
      "loss": 0.0009,
      "step": 213
    },
    {
      "epoch": 71.0,
      "eval_loss": 0.0003927021516574314,
      "step": 213
    },
    {
      "epoch": 72.0,
      "grad_norm": 0.019543109461665154,
      "learning_rate": 7.111111111111112e-05,
      "loss": 0.0005,
      "step": 216
    },
    {
      "epoch": 72.0,
      "eval_loss": 0.00021264032875478733,
      "step": 216
    },
    {
      "epoch": 73.0,
      "grad_norm": 0.0056623355485498905,
      "learning_rate": 7.055555555555556e-05,
      "loss": 0.0006,
      "step": 219
    },
    {
      "epoch": 73.0,
      "eval_loss": 0.0021661626145942138,
      "step": 219
    },
    {
      "epoch": 74.0,
      "grad_norm": 0.019625581800937653,
      "learning_rate": 7e-05,
      "loss": 0.0011,
      "step": 222
    },
    {
      "epoch": 74.0,
      "eval_loss": 0.00024185489528463222,
      "step": 222
    },
    {
      "epoch": 75.0,
      "grad_norm": 0.03349529206752777,
      "learning_rate": 6.944444444444444e-05,
      "loss": 0.0004,
      "step": 225
    },
    {
      "epoch": 75.0,
      "eval_loss": 0.00044701015467580875,
      "step": 225
    },
    {
      "epoch": 76.0,
      "grad_norm": 0.02077067829668522,
      "learning_rate": 6.88888888888889e-05,
      "loss": 0.0005,
      "step": 228
    },
    {
      "epoch": 76.0,
      "eval_loss": 0.00046896050534996905,
      "step": 228
    },
    {
      "epoch": 77.0,
      "grad_norm": 0.02283375710248947,
      "learning_rate": 6.833333333333333e-05,
      "loss": 0.0004,
      "step": 231
    },
    {
      "epoch": 77.0,
      "eval_loss": 0.00041128918310278094,
      "step": 231
    },
    {
      "epoch": 78.0,
      "grad_norm": 0.016250312328338623,
      "learning_rate": 6.777777777777778e-05,
      "loss": 0.0005,
      "step": 234
    },
    {
      "epoch": 78.0,
      "eval_loss": 0.0003635370609117672,
      "step": 234
    },
    {
      "epoch": 79.0,
      "grad_norm": 0.01647595688700676,
      "learning_rate": 6.722222222222223e-05,
      "loss": 0.0005,
      "step": 237
    },
    {
      "epoch": 79.0,
      "eval_loss": 0.0002689508435651078,
      "step": 237
    },
    {
      "epoch": 80.0,
      "grad_norm": 0.028595076873898506,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.0004,
      "step": 240
    },
    {
      "epoch": 80.0,
      "eval_loss": 0.00030899126795702614,
      "step": 240
    },
    {
      "epoch": 81.0,
      "grad_norm": 0.01860808953642845,
      "learning_rate": 6.611111111111111e-05,
      "loss": 0.0004,
      "step": 243
    },
    {
      "epoch": 81.0,
      "eval_loss": 0.0002056151228316594,
      "step": 243
    },
    {
      "epoch": 82.0,
      "grad_norm": 0.014489112421870232,
      "learning_rate": 6.555555555555556e-05,
      "loss": 0.0007,
      "step": 246
    },
    {
      "epoch": 82.0,
      "eval_loss": 0.00045135094078432305,
      "step": 246
    },
    {
      "epoch": 83.0,
      "grad_norm": 0.024521389976143837,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.0003,
      "step": 249
    },
    {
      "epoch": 83.0,
      "eval_loss": 0.0002208272613643203,
      "step": 249
    },
    {
      "epoch": 84.0,
      "grad_norm": 0.02429359033703804,
      "learning_rate": 6.444444444444446e-05,
      "loss": 0.001,
      "step": 252
    },
    {
      "epoch": 84.0,
      "eval_loss": 0.00021639598089677746,
      "step": 252
    },
    {
      "epoch": 85.0,
      "grad_norm": 0.019756706431508064,
      "learning_rate": 6.388888888888888e-05,
      "loss": 0.0004,
      "step": 255
    },
    {
      "epoch": 85.0,
      "eval_loss": 0.00026886678006121656,
      "step": 255
    },
    {
      "epoch": 86.0,
      "grad_norm": 0.013586354441940784,
      "learning_rate": 6.333333333333333e-05,
      "loss": 0.0004,
      "step": 258
    },
    {
      "epoch": 86.0,
      "eval_loss": 0.0003126749868897605,
      "step": 258
    },
    {
      "epoch": 87.0,
      "grad_norm": 0.01784118264913559,
      "learning_rate": 6.277777777777778e-05,
      "loss": 0.0005,
      "step": 261
    },
    {
      "epoch": 87.0,
      "eval_loss": 0.000416537963974406,
      "step": 261
    },
    {
      "epoch": 88.0,
      "grad_norm": 0.007072989363223314,
      "learning_rate": 6.222222222222222e-05,
      "loss": 0.0004,
      "step": 264
    },
    {
      "epoch": 88.0,
      "eval_loss": 0.00032800980861793507,
      "step": 264
    },
    {
      "epoch": 89.0,
      "grad_norm": 0.006732949987053871,
      "learning_rate": 6.166666666666667e-05,
      "loss": 0.0004,
      "step": 267
    },
    {
      "epoch": 89.0,
      "eval_loss": 0.00022516869776154636,
      "step": 267
    },
    {
      "epoch": 90.0,
      "grad_norm": 0.0077280462719500065,
      "learning_rate": 6.111111111111112e-05,
      "loss": 0.0008,
      "step": 270
    },
    {
      "epoch": 90.0,
      "eval_loss": 0.00024473566008964553,
      "step": 270
    },
    {
      "epoch": 91.0,
      "grad_norm": 0.015744872391223907,
      "learning_rate": 6.055555555555555e-05,
      "loss": 0.0003,
      "step": 273
    },
    {
      "epoch": 91.0,
      "eval_loss": 0.023768854720583477,
      "step": 273
    },
    {
      "epoch": 92.0,
      "grad_norm": 0.02426566742360592,
      "learning_rate": 6e-05,
      "loss": 0.0006,
      "step": 276
    },
    {
      "epoch": 92.0,
      "eval_loss": 0.0002206413548265118,
      "step": 276
    },
    {
      "epoch": 93.0,
      "grad_norm": 0.016178347170352936,
      "learning_rate": 5.9444444444444445e-05,
      "loss": 0.0003,
      "step": 279
    },
    {
      "epoch": 93.0,
      "eval_loss": 0.0002218185150923091,
      "step": 279
    },
    {
      "epoch": 94.0,
      "grad_norm": 0.015018248930573463,
      "learning_rate": 5.8888888888888896e-05,
      "loss": 0.0004,
      "step": 282
    },
    {
      "epoch": 94.0,
      "eval_loss": 0.0003973171797042596,
      "step": 282
    },
    {
      "epoch": 95.0,
      "grad_norm": 0.01616276428103447,
      "learning_rate": 5.833333333333334e-05,
      "loss": 0.0004,
      "step": 285
    },
    {
      "epoch": 95.0,
      "eval_loss": 0.00031747142793392413,
      "step": 285
    },
    {
      "epoch": 96.0,
      "grad_norm": 0.014824386686086655,
      "learning_rate": 5.7777777777777776e-05,
      "loss": 0.0003,
      "step": 288
    },
    {
      "epoch": 96.0,
      "eval_loss": 0.0018828584300536022,
      "step": 288
    },
    {
      "epoch": 97.0,
      "grad_norm": 0.03257814422249794,
      "learning_rate": 5.722222222222222e-05,
      "loss": 0.0003,
      "step": 291
    },
    {
      "epoch": 97.0,
      "eval_loss": 0.0003312543978609028,
      "step": 291
    },
    {
      "epoch": 98.0,
      "grad_norm": 0.022597268223762512,
      "learning_rate": 5.666666666666667e-05,
      "loss": 0.0004,
      "step": 294
    },
    {
      "epoch": 98.0,
      "eval_loss": 0.0001695478263172845,
      "step": 294
    },
    {
      "epoch": 99.0,
      "grad_norm": 0.018441416323184967,
      "learning_rate": 5.6111111111111114e-05,
      "loss": 0.0004,
      "step": 297
    },
    {
      "epoch": 99.0,
      "eval_loss": 0.00027654807854560204,
      "step": 297
    },
    {
      "epoch": 100.0,
      "grad_norm": 0.009203116409480572,
      "learning_rate": 5.555555555555556e-05,
      "loss": 0.0003,
      "step": 300
    },
    {
      "epoch": 100.0,
      "eval_loss": 0.0002806745359521301,
      "step": 300
    },
    {
      "epoch": 101.0,
      "grad_norm": 0.013606158085167408,
      "learning_rate": 5.500000000000001e-05,
      "loss": 0.0004,
      "step": 303
    },
    {
      "epoch": 101.0,
      "eval_loss": 0.00012689381537711597,
      "step": 303
    },
    {
      "epoch": 102.0,
      "grad_norm": 0.028007537126541138,
      "learning_rate": 5.4444444444444446e-05,
      "loss": 0.0004,
      "step": 306
    },
    {
      "epoch": 102.0,
      "eval_loss": 0.00021133967538844445,
      "step": 306
    },
    {
      "epoch": 103.0,
      "grad_norm": 0.0277783814817667,
      "learning_rate": 5.388888888888889e-05,
      "loss": 0.0003,
      "step": 309
    },
    {
      "epoch": 103.0,
      "eval_loss": 0.00017610619306651643,
      "step": 309
    },
    {
      "epoch": 104.0,
      "grad_norm": 0.034732718020677567,
      "learning_rate": 5.333333333333333e-05,
      "loss": 0.0007,
      "step": 312
    },
    {
      "epoch": 104.0,
      "eval_loss": 0.0002040345806562982,
      "step": 312
    },
    {
      "epoch": 105.0,
      "grad_norm": 0.011287577450275421,
      "learning_rate": 5.2777777777777784e-05,
      "loss": 0.0002,
      "step": 315
    },
    {
      "epoch": 105.0,
      "eval_loss": 0.000689185353803623,
      "step": 315
    },
    {
      "epoch": 106.0,
      "grad_norm": 0.004630766808986664,
      "learning_rate": 5.222222222222223e-05,
      "loss": 0.0008,
      "step": 318
    },
    {
      "epoch": 106.0,
      "eval_loss": 0.0002685395120352041,
      "step": 318
    },
    {
      "epoch": 107.0,
      "grad_norm": 0.012894059531390667,
      "learning_rate": 5.166666666666667e-05,
      "loss": 0.0002,
      "step": 321
    },
    {
      "epoch": 107.0,
      "eval_loss": 0.00046761837829762954,
      "step": 321
    },
    {
      "epoch": 108.0,
      "grad_norm": 0.005289476364850998,
      "learning_rate": 5.111111111111111e-05,
      "loss": 0.0005,
      "step": 324
    },
    {
      "epoch": 108.0,
      "eval_loss": 0.0004955679035447246,
      "step": 324
    },
    {
      "epoch": 109.0,
      "grad_norm": 0.008775963447988033,
      "learning_rate": 5.055555555555556e-05,
      "loss": 0.0004,
      "step": 327
    },
    {
      "epoch": 109.0,
      "eval_loss": 0.0003132137913780753,
      "step": 327
    },
    {
      "epoch": 110.0,
      "grad_norm": 0.008944888599216938,
      "learning_rate": 5e-05,
      "loss": 0.0003,
      "step": 330
    },
    {
      "epoch": 110.0,
      "eval_loss": 0.0002601714220872964,
      "step": 330
    },
    {
      "epoch": 111.0,
      "grad_norm": 0.011603083461523056,
      "learning_rate": 4.9444444444444446e-05,
      "loss": 0.0007,
      "step": 333
    },
    {
      "epoch": 111.0,
      "eval_loss": 0.00020239304049027851,
      "step": 333
    },
    {
      "epoch": 112.0,
      "grad_norm": 0.00776999955996871,
      "learning_rate": 4.888888888888889e-05,
      "loss": 0.0004,
      "step": 336
    },
    {
      "epoch": 112.0,
      "eval_loss": 0.00014907265203873977,
      "step": 336
    },
    {
      "epoch": 113.0,
      "grad_norm": 0.0255650132894516,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 0.0003,
      "step": 339
    },
    {
      "epoch": 113.0,
      "eval_loss": 0.00015778529368617455,
      "step": 339
    },
    {
      "epoch": 114.0,
      "grad_norm": 0.011584856547415257,
      "learning_rate": 4.7777777777777784e-05,
      "loss": 0.0003,
      "step": 342
    },
    {
      "epoch": 114.0,
      "eval_loss": 0.0010641510597451998,
      "step": 342
    },
    {
      "epoch": 115.0,
      "grad_norm": 0.009894181974232197,
      "learning_rate": 4.722222222222222e-05,
      "loss": 0.0003,
      "step": 345
    },
    {
      "epoch": 115.0,
      "eval_loss": 0.00048184302449953974,
      "step": 345
    },
    {
      "epoch": 116.0,
      "grad_norm": 0.005677651613950729,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.0002,
      "step": 348
    },
    {
      "epoch": 116.0,
      "eval_loss": 0.00016447758316644466,
      "step": 348
    },
    {
      "epoch": 117.0,
      "grad_norm": 0.004759891424328089,
      "learning_rate": 4.6111111111111115e-05,
      "loss": 0.0002,
      "step": 351
    },
    {
      "epoch": 117.0,
      "eval_loss": 0.00017703152616377338,
      "step": 351
    },
    {
      "epoch": 118.0,
      "grad_norm": 0.005718844477087259,
      "learning_rate": 4.555555555555556e-05,
      "loss": 0.0007,
      "step": 354
    },
    {
      "epoch": 118.0,
      "eval_loss": 0.00016501169939147075,
      "step": 354
    },
    {
      "epoch": 119.0,
      "grad_norm": 0.008282499387860298,
      "learning_rate": 4.5e-05,
      "loss": 0.0002,
      "step": 357
    },
    {
      "epoch": 119.0,
      "eval_loss": 0.0004331534935772652,
      "step": 357
    },
    {
      "epoch": 120.0,
      "grad_norm": 0.011155192740261555,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.0009,
      "step": 360
    },
    {
      "epoch": 120.0,
      "eval_loss": 0.0001141832124631037,
      "step": 360
    },
    {
      "epoch": 121.0,
      "grad_norm": 0.005778059363365173,
      "learning_rate": 4.388888888888889e-05,
      "loss": 0.0003,
      "step": 363
    },
    {
      "epoch": 121.0,
      "eval_loss": 0.00040531081058361453,
      "step": 363
    },
    {
      "epoch": 122.0,
      "grad_norm": 0.005320142488926649,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.0007,
      "step": 366
    },
    {
      "epoch": 122.0,
      "eval_loss": 0.0010269531829180778,
      "step": 366
    },
    {
      "epoch": 123.0,
      "grad_norm": 0.007754209451377392,
      "learning_rate": 4.277777777777778e-05,
      "loss": 0.0003,
      "step": 369
    },
    {
      "epoch": 123.0,
      "eval_loss": 0.00017903023144754114,
      "step": 369
    },
    {
      "epoch": 124.0,
      "grad_norm": 0.006416998337954283,
      "learning_rate": 4.222222222222222e-05,
      "loss": 0.0003,
      "step": 372
    },
    {
      "epoch": 124.0,
      "eval_loss": 0.00027484474712764496,
      "step": 372
    },
    {
      "epoch": 125.0,
      "grad_norm": 0.024970753118395805,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.0003,
      "step": 375
    },
    {
      "epoch": 125.0,
      "eval_loss": 0.00022123561348053045,
      "step": 375
    },
    {
      "epoch": 126.0,
      "grad_norm": 0.00821270514279604,
      "learning_rate": 4.111111111111111e-05,
      "loss": 0.0003,
      "step": 378
    },
    {
      "epoch": 126.0,
      "eval_loss": 0.0003349211053318868,
      "step": 378
    },
    {
      "epoch": 127.0,
      "grad_norm": 0.0064018601551651955,
      "learning_rate": 4.055555555555556e-05,
      "loss": 0.0003,
      "step": 381
    },
    {
      "epoch": 127.0,
      "eval_loss": 0.0001567363558024226,
      "step": 381
    },
    {
      "epoch": 128.0,
      "grad_norm": 0.012064468115568161,
      "learning_rate": 4e-05,
      "loss": 0.0003,
      "step": 384
    },
    {
      "epoch": 128.0,
      "eval_loss": 0.0002829583007041947,
      "step": 384
    },
    {
      "epoch": 129.0,
      "grad_norm": 0.017789853736758232,
      "learning_rate": 3.944444444444445e-05,
      "loss": 0.0003,
      "step": 387
    },
    {
      "epoch": 129.0,
      "eval_loss": 0.00016666978144712629,
      "step": 387
    },
    {
      "epoch": 130.0,
      "grad_norm": 0.01040696818381548,
      "learning_rate": 3.888888888888889e-05,
      "loss": 0.0002,
      "step": 390
    },
    {
      "epoch": 130.0,
      "eval_loss": 0.00031477663296755056,
      "step": 390
    },
    {
      "epoch": 131.0,
      "grad_norm": 0.010149514302611351,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 0.0003,
      "step": 393
    },
    {
      "epoch": 131.0,
      "eval_loss": 0.00021804848156534718,
      "step": 393
    },
    {
      "epoch": 132.0,
      "grad_norm": 0.00978134386241436,
      "learning_rate": 3.777777777777778e-05,
      "loss": 0.0003,
      "step": 396
    },
    {
      "epoch": 132.0,
      "eval_loss": 0.0001527289855403069,
      "step": 396
    },
    {
      "epoch": 133.0,
      "grad_norm": 0.01463249884545803,
      "learning_rate": 3.722222222222222e-05,
      "loss": 0.0003,
      "step": 399
    },
    {
      "epoch": 133.0,
      "eval_loss": 0.0003355635180923855,
      "step": 399
    },
    {
      "epoch": 134.0,
      "grad_norm": 0.007559162564575672,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.0002,
      "step": 402
    },
    {
      "epoch": 134.0,
      "eval_loss": 0.0003239563029637793,
      "step": 402
    },
    {
      "epoch": 135.0,
      "grad_norm": 0.0152662368491292,
      "learning_rate": 3.611111111111111e-05,
      "loss": 0.0009,
      "step": 405
    },
    {
      "epoch": 135.0,
      "eval_loss": 0.000578267775108543,
      "step": 405
    },
    {
      "epoch": 136.0,
      "grad_norm": 0.007867678999900818,
      "learning_rate": 3.555555555555556e-05,
      "loss": 0.0002,
      "step": 408
    },
    {
      "epoch": 136.0,
      "eval_loss": 0.00014525715723721078,
      "step": 408
    },
    {
      "epoch": 137.0,
      "grad_norm": 0.006671692710369825,
      "learning_rate": 3.5e-05,
      "loss": 0.0004,
      "step": 411
    },
    {
      "epoch": 137.0,
      "eval_loss": 0.0003618602891947376,
      "step": 411
    },
    {
      "epoch": 138.0,
      "grad_norm": 0.005246744956821203,
      "learning_rate": 3.444444444444445e-05,
      "loss": 0.0004,
      "step": 414
    },
    {
      "epoch": 138.0,
      "eval_loss": 0.0014481925750260416,
      "step": 414
    },
    {
      "epoch": 139.0,
      "grad_norm": 0.009685051627457142,
      "learning_rate": 3.388888888888889e-05,
      "loss": 0.0004,
      "step": 417
    },
    {
      "epoch": 139.0,
      "eval_loss": 0.00020952508393747848,
      "step": 417
    },
    {
      "epoch": 140.0,
      "grad_norm": 0.005827026907354593,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.0003,
      "step": 420
    },
    {
      "epoch": 140.0,
      "eval_loss": 0.00016750711038184817,
      "step": 420
    },
    {
      "epoch": 141.0,
      "grad_norm": 0.007846711203455925,
      "learning_rate": 3.277777777777778e-05,
      "loss": 0.0003,
      "step": 423
    },
    {
      "epoch": 141.0,
      "eval_loss": 0.00025348443632537964,
      "step": 423
    },
    {
      "epoch": 142.0,
      "grad_norm": 0.013789074495434761,
      "learning_rate": 3.222222222222223e-05,
      "loss": 0.0003,
      "step": 426
    },
    {
      "epoch": 142.0,
      "eval_loss": 8.392077643293305e-05,
      "step": 426
    },
    {
      "epoch": 143.0,
      "grad_norm": 0.007018670905381441,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 0.0003,
      "step": 429
    },
    {
      "epoch": 143.0,
      "eval_loss": 0.00033740595763447344,
      "step": 429
    },
    {
      "epoch": 144.0,
      "grad_norm": 0.008040185086429119,
      "learning_rate": 3.111111111111111e-05,
      "loss": 0.0003,
      "step": 432
    },
    {
      "epoch": 144.0,
      "eval_loss": 0.00024851112002579614,
      "step": 432
    },
    {
      "epoch": 145.0,
      "grad_norm": 0.009950034320354462,
      "learning_rate": 3.055555555555556e-05,
      "loss": 0.0003,
      "step": 435
    },
    {
      "epoch": 145.0,
      "eval_loss": 0.0001685441024164902,
      "step": 435
    },
    {
      "epoch": 146.0,
      "grad_norm": 0.013770325109362602,
      "learning_rate": 3e-05,
      "loss": 0.0003,
      "step": 438
    },
    {
      "epoch": 146.0,
      "eval_loss": 0.001287613036492985,
      "step": 438
    },
    {
      "epoch": 147.0,
      "grad_norm": 0.01432884857058525,
      "learning_rate": 2.9444444444444448e-05,
      "loss": 0.0003,
      "step": 441
    },
    {
      "epoch": 147.0,
      "eval_loss": 0.0016738660382543459,
      "step": 441
    },
    {
      "epoch": 148.0,
      "grad_norm": 0.015603102743625641,
      "learning_rate": 2.8888888888888888e-05,
      "loss": 0.0003,
      "step": 444
    },
    {
      "epoch": 148.0,
      "eval_loss": 0.0002806512165079766,
      "step": 444
    },
    {
      "epoch": 149.0,
      "grad_norm": 0.009181847795844078,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 0.0008,
      "step": 447
    },
    {
      "epoch": 149.0,
      "eval_loss": 0.00017635445856285515,
      "step": 447
    },
    {
      "epoch": 150.0,
      "grad_norm": 0.01117109414190054,
      "learning_rate": 2.777777777777778e-05,
      "loss": 0.0009,
      "step": 450
    },
    {
      "epoch": 150.0,
      "eval_loss": 0.00024875619101294433,
      "step": 450
    },
    {
      "epoch": 151.0,
      "grad_norm": 0.008653705939650536,
      "learning_rate": 2.7222222222222223e-05,
      "loss": 0.0003,
      "step": 453
    },
    {
      "epoch": 151.0,
      "eval_loss": 0.00021073120442451909,
      "step": 453
    },
    {
      "epoch": 152.0,
      "grad_norm": 0.013539256528019905,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.0002,
      "step": 456
    },
    {
      "epoch": 152.0,
      "eval_loss": 0.00018362480541327385,
      "step": 456
    },
    {
      "epoch": 153.0,
      "grad_norm": 0.0076017919927835464,
      "learning_rate": 2.6111111111111114e-05,
      "loss": 0.0003,
      "step": 459
    },
    {
      "epoch": 153.0,
      "eval_loss": 0.0002814715944623458,
      "step": 459
    },
    {
      "epoch": 154.0,
      "grad_norm": 0.009367631748318672,
      "learning_rate": 2.5555555555555554e-05,
      "loss": 0.0003,
      "step": 462
    },
    {
      "epoch": 154.0,
      "eval_loss": 0.00019835300408885815,
      "step": 462
    },
    {
      "epoch": 155.0,
      "grad_norm": 0.010122010484337807,
      "learning_rate": 2.5e-05,
      "loss": 0.0003,
      "step": 465
    },
    {
      "epoch": 155.0,
      "eval_loss": 0.00024758470617598506,
      "step": 465
    },
    {
      "epoch": 156.0,
      "grad_norm": 0.007423652336001396,
      "learning_rate": 2.4444444444444445e-05,
      "loss": 0.0005,
      "step": 468
    },
    {
      "epoch": 156.0,
      "eval_loss": 0.0007786828585267358,
      "step": 468
    },
    {
      "epoch": 157.0,
      "grad_norm": 0.008501683361828327,
      "learning_rate": 2.3888888888888892e-05,
      "loss": 0.0002,
      "step": 471
    },
    {
      "epoch": 157.0,
      "eval_loss": 0.0002010888050790527,
      "step": 471
    },
    {
      "epoch": 158.0,
      "grad_norm": 0.0043980577029287815,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 0.0003,
      "step": 474
    },
    {
      "epoch": 158.0,
      "eval_loss": 0.00015015287799542422,
      "step": 474
    },
    {
      "epoch": 159.0,
      "grad_norm": 0.006685655098408461,
      "learning_rate": 2.277777777777778e-05,
      "loss": 0.0003,
      "step": 477
    },
    {
      "epoch": 159.0,
      "eval_loss": 0.000183925104647642,
      "step": 477
    },
    {
      "epoch": 160.0,
      "grad_norm": 0.006814225576817989,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.0003,
      "step": 480
    },
    {
      "epoch": 160.0,
      "eval_loss": 0.00016786724418125232,
      "step": 480
    },
    {
      "epoch": 161.0,
      "grad_norm": 0.010814142413437366,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 0.0008,
      "step": 483
    },
    {
      "epoch": 161.0,
      "eval_loss": 0.00021212245173956034,
      "step": 483
    },
    {
      "epoch": 162.0,
      "grad_norm": 0.006005243398249149,
      "learning_rate": 2.111111111111111e-05,
      "loss": 0.0005,
      "step": 486
    },
    {
      "epoch": 162.0,
      "eval_loss": 0.00020819301480514695,
      "step": 486
    },
    {
      "epoch": 163.0,
      "grad_norm": 0.009625655598938465,
      "learning_rate": 2.0555555555555555e-05,
      "loss": 0.0006,
      "step": 489
    },
    {
      "epoch": 163.0,
      "eval_loss": 0.00018005424835791927,
      "step": 489
    },
    {
      "epoch": 164.0,
      "grad_norm": 0.020065464079380035,
      "learning_rate": 2e-05,
      "loss": 0.001,
      "step": 492
    },
    {
      "epoch": 164.0,
      "eval_loss": 0.0001432490380921081,
      "step": 492
    },
    {
      "epoch": 165.0,
      "grad_norm": 0.013735084794461727,
      "learning_rate": 1.9444444444444445e-05,
      "loss": 0.0003,
      "step": 495
    },
    {
      "epoch": 165.0,
      "eval_loss": 0.0002956178650492802,
      "step": 495
    },
    {
      "epoch": 166.0,
      "grad_norm": 0.0022049210965633392,
      "learning_rate": 1.888888888888889e-05,
      "loss": 0.0003,
      "step": 498
    },
    {
      "epoch": 166.0,
      "eval_loss": 0.00019969587729065096,
      "step": 498
    },
    {
      "epoch": 167.0,
      "grad_norm": 0.012128585949540138,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 0.0003,
      "step": 501
    },
    {
      "epoch": 167.0,
      "eval_loss": 0.00019011754866369302,
      "step": 501
    },
    {
      "epoch": 168.0,
      "grad_norm": 0.0155837032943964,
      "learning_rate": 1.777777777777778e-05,
      "loss": 0.0006,
      "step": 504
    },
    {
      "epoch": 168.0,
      "eval_loss": 0.0006984440852647822,
      "step": 504
    },
    {
      "epoch": 169.0,
      "grad_norm": 0.007251424714922905,
      "learning_rate": 1.7222222222222224e-05,
      "loss": 0.0003,
      "step": 507
    },
    {
      "epoch": 169.0,
      "eval_loss": 0.00024200527077482547,
      "step": 507
    },
    {
      "epoch": 170.0,
      "grad_norm": 0.009954740293323994,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0002,
      "step": 510
    },
    {
      "epoch": 170.0,
      "eval_loss": 0.00017585106952537898,
      "step": 510
    },
    {
      "epoch": 171.0,
      "grad_norm": 0.0070372638292610645,
      "learning_rate": 1.6111111111111115e-05,
      "loss": 0.0002,
      "step": 513
    },
    {
      "epoch": 171.0,
      "eval_loss": 0.00023796418290658038,
      "step": 513
    },
    {
      "epoch": 172.0,
      "grad_norm": 0.00483382772654295,
      "learning_rate": 1.5555555555555555e-05,
      "loss": 0.0002,
      "step": 516
    },
    {
      "epoch": 172.0,
      "eval_loss": 0.0001372016445202462,
      "step": 516
    },
    {
      "epoch": 173.0,
      "grad_norm": 0.019365299493074417,
      "learning_rate": 1.5e-05,
      "loss": 0.0006,
      "step": 519
    },
    {
      "epoch": 173.0,
      "eval_loss": 0.00030773005328228465,
      "step": 519
    },
    {
      "epoch": 174.0,
      "grad_norm": 0.008782112039625645,
      "learning_rate": 1.4444444444444444e-05,
      "loss": 0.0004,
      "step": 522
    },
    {
      "epoch": 174.0,
      "eval_loss": 0.0021769343726191436,
      "step": 522
    },
    {
      "epoch": 175.0,
      "grad_norm": 0.004565723706036806,
      "learning_rate": 1.388888888888889e-05,
      "loss": 0.0003,
      "step": 525
    },
    {
      "epoch": 175.0,
      "eval_loss": 0.0002195145347286598,
      "step": 525
    },
    {
      "epoch": 176.0,
      "grad_norm": 0.007128484081476927,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0004,
      "step": 528
    },
    {
      "epoch": 176.0,
      "eval_loss": 0.0001996038642118947,
      "step": 528
    },
    {
      "epoch": 177.0,
      "grad_norm": 0.0037808073684573174,
      "learning_rate": 1.2777777777777777e-05,
      "loss": 0.0002,
      "step": 531
    },
    {
      "epoch": 177.0,
      "eval_loss": 0.0003166236009747081,
      "step": 531
    },
    {
      "epoch": 178.0,
      "grad_norm": 0.010984227061271667,
      "learning_rate": 1.2222222222222222e-05,
      "loss": 0.002,
      "step": 534
    },
    {
      "epoch": 178.0,
      "eval_loss": 0.00013841488716934692,
      "step": 534
    },
    {
      "epoch": 179.0,
      "grad_norm": 0.005308511666953564,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 0.0003,
      "step": 537
    },
    {
      "epoch": 179.0,
      "eval_loss": 0.00022778473439757362,
      "step": 537
    },
    {
      "epoch": 180.0,
      "grad_norm": 0.0030930081848055124,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 0.0004,
      "step": 540
    },
    {
      "epoch": 180.0,
      "eval_loss": 0.00016108043091662695,
      "step": 540
    },
    {
      "epoch": 181.0,
      "grad_norm": 0.005531292408704758,
      "learning_rate": 1.0555555555555555e-05,
      "loss": 0.0003,
      "step": 543
    },
    {
      "epoch": 181.0,
      "eval_loss": 0.00018386762067166274,
      "step": 543
    },
    {
      "epoch": 182.0,
      "grad_norm": 0.003314254805445671,
      "learning_rate": 1e-05,
      "loss": 0.0002,
      "step": 546
    },
    {
      "epoch": 182.0,
      "eval_loss": 0.00021343043745218891,
      "step": 546
    },
    {
      "epoch": 183.0,
      "grad_norm": 0.0024922636803239584,
      "learning_rate": 9.444444444444445e-06,
      "loss": 0.0002,
      "step": 549
    },
    {
      "epoch": 183.0,
      "eval_loss": 0.000291232551990106,
      "step": 549
    },
    {
      "epoch": 184.0,
      "grad_norm": 0.003388673299923539,
      "learning_rate": 8.88888888888889e-06,
      "loss": 0.0002,
      "step": 552
    },
    {
      "epoch": 184.0,
      "eval_loss": 0.0003547071451521333,
      "step": 552
    },
    {
      "epoch": 185.0,
      "grad_norm": 0.003948461730033159,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.0002,
      "step": 555
    },
    {
      "epoch": 185.0,
      "eval_loss": 0.00012169219867246284,
      "step": 555
    }
  ],
  "logging_steps": 500,
  "max_steps": 600,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 200,
  "save_steps": 500,
  "total_flos": 169569638400000.0,
  "train_batch_size": 254,
  "trial_name": null,
  "trial_params": null
}
